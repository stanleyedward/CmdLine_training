{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch_modules'...\n",
      "remote: Enumerating objects: 70, done.\u001b[K\n",
      "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 70 (delta 24), reused 61 (delta 15), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (70/70), 24.40 KiB | 8.13 MiB/s, done.\n",
      "Resolving deltas: 100% (24/24), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/stanleyedward/pytorch_modules.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "def download_data(source: str, \n",
    "                  destination: str,\n",
    "                  remove_source: bool = True) -> Path:\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download pizza, steak, sushi data\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "\n",
    "        # Unzip pizza, steak, sushi data\n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove .zip file\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv pytorch_modules/modules/train.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv pytorch_modules/modules/prediction.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training a model with: \n",
      "epochs 5 \n",
      "batch_size 128 \n",
      "hidden_units 128\n",
      " learning_rate 0.0003\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.0997 | train_acc: 0.3212 | test_loss: 1.0952 | test_acc: 0.3047\n",
      " 20%|█████████                                    | 1/5 [00:01<00:07,  1.91s/it]Epoch: 2 | train_loss: 1.0937 | train_acc: 0.3315 | test_loss: 1.0808 | test_acc: 0.3514\n",
      " 40%|██████████████████                           | 2/5 [00:03<00:05,  1.71s/it]Epoch: 3 | train_loss: 1.0771 | train_acc: 0.3978 | test_loss: 1.0700 | test_acc: 0.3384\n",
      " 60%|███████████████████████████                  | 3/5 [00:05<00:03,  1.65s/it]Epoch: 4 | train_loss: 1.0514 | train_acc: 0.3885 | test_loss: 1.0222 | test_acc: 0.6271\n",
      " 80%|████████████████████████████████████         | 4/5 [00:06<00:01,  1.64s/it]Epoch: 5 | train_loss: 1.0298 | train_acc: 0.5471 | test_loss: 0.9701 | test_acc: 0.6258\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:08<00:00,  1.66s/it]\n",
      "[INFO] Saving model to: models/dummy_model.pth\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 5 --batch_size 128 --hidden_units 128 --lr 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on data/pizza_steak_sushi/test/sushi/175783.jpg\n",
      "[INFO] Loading in model from: models/dummy_model.pth\n",
      "/usr/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "[INFO] Pred class: sushi, Pred prob: 0.379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python prediction.py --image data/pizza_steak_sushi/test/sushi/175783.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
